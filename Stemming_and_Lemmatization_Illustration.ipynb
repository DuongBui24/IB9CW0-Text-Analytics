{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgCACT8kapAp22Je5FTt21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9CW0-Text-Analytics/blob/main/Stemming_and_Lemmatization_Illustration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "4cvYKHhF4PwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"run\", \"ran\", \"running\"]"
      ],
      "metadata": {
        "id": "gtXnMBjh6_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSMUyigS3vO9"
      },
      "outputs": [],
      "source": [
        "text = [\"are\", \"am\", \"being\",\"been\",\"be\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"cars\",\"car's\",\"cars\"]"
      ],
      "metadata": {
        "id": "_RHLS_hh57XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"happy\",\"happiness\",\"happily\"]"
      ],
      "metadata": {
        "id": "v8x3IV996wcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stem_words = [stemmer.stem(word) for word in text]\n",
        "stem_words"
      ],
      "metadata": {
        "id": "rEtQ-od16Epd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatized_text = [lemmatizer.lemmatize(word,pos=\"v\") for word in text]\n",
        "lemmatized_text"
      ],
      "metadata": {
        "id": "lnRSvrZ15DVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "eefjF6U98i-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_text = pos_tag(text)\n",
        "tagged_text"
      ],
      "metadata": {
        "id": "2q214PS_81-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the POS tags\n",
        "modified_text = [(word, tag[0].lower()) for word, tag in tagged_text]\n",
        "modified_text"
      ],
      "metadata": {
        "id": "AjtojoqhAfbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_text = [lemmatizer.lemmatize(word,pos=tag) for word,tag in modified_text]\n",
        "lemmatized_text"
      ],
      "metadata": {
        "id": "QIQYnwwtA7Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# POS tagging\n",
        "tagged_text = pos_tag(text)\n",
        "\n",
        "# Function to map NLTK POS tags to WordNet POS tags\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return 'a'  # adjective\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return 'v'  # verb\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return 'n'  # noun\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return 'r'  # adverb\n",
        "    else:\n",
        "        return 'n'  # Default to noun if not matched\n",
        "\n",
        "# Modify the POS tags\n",
        "modified_text = [(word, get_wordnet_pos(tag)) for word, tag in tagged_text]\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize with correct POS tags\n",
        "lemmatized_text = [lemmatizer.lemmatize(word, pos=tag) for word, tag in modified_text]\n",
        "\n",
        "lemmatized_text\n"
      ],
      "metadata": {
        "id": "qdj7ur3GCD7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}